---
title: Unconstrained Optimization
category: Optimization
---

Conditions
===

Necessary conditions for opimality are derived by assuming that $x^{\ast}$ is a local minimizer and then proving facts about $\nabla f(x^{\ast})$ and $\nabla^2f(x^{\ast})$.

First-Order Necessary Conditions
---

If $x^\ast$ is a local minimizer and $f$ is continuously differentiable in an open neighborhood of $x^\ast$, then $\nabla f(x^\ast)=0$.

We call $x^{\ast}$ a stationary point if $\nabla f(x^{\ast})=0$. According to the theorem above, any local minimizer must be a stationary point.

Second-Order Necessary Conditions
---

We recall that a matrix $B$ is positive definite if $p^TBp>0$ for all $p\neq0$, and positive semidefinite if $p^TBp\geq0$ for all $p$.

If $x^\ast$ is a local minimizer of $f$ and $\nabla^2f$ exists and is continous in an open neighborhood of $x^\ast$, then $\nabla f(x^\ast)=0$ and $\nabla^2f(x^\ast)$ is positive semidefinite.

Second-Order Sufficient Conditions
---

Sufficient conditions, which are conditions on the derivatives of $f$ at the point $z^{\ast}$ that guarantee that $x^{\ast}$ is a local minimizer.

Suppose that $\nabla^2f$ is continuous in an open neighborhood of $x^\ast$ and that $\nabla f(x^\ast)=0$ and $\nabla^2f(x^\ast)$ is positive definite. Then $x^\ast$ is a strict local minimizer of $f$.

When $f$ is convex, any local minimizer $x^\ast$ is a global minimizer of $f$. If in addition $f$ is differentiable, then any stationary point $x^\ast$ is a global minimizer of $f$.

Overview of Algorithms
===

All algorithms for unconstrained minimization require that user to supply a starting point, which we usually denote by $x_0$.

Beginning at $x_ 0$, optimization algorithms generate a squence of iterates $\{x_k\}^{\infty}_{k=0}$ that terminate when either no more progress can be made or when it seems that a solution point has been approximated with sufficient accuracy.

These are two fundamental strategies for moving from the current point $x_ k$ to a new iterate $x_ {k+1}$ with a lower function value that $x_k$: Line Search and Trust Region.

Line Search
---

In line search strategy, the algorithms choose a direction $p_k$ and searches along this direction from the current iterate $x_k$ for a new iterate.

The distance to move along $p_k$, or the step length $\alpha$, can be found by solving the one-dimesional minimization problem:

$$\min_{\alpha>0}f(x_k+\alpha p_k)$$

### Search Direction

1. **The steepest descent method** is a line search method that move along $p_k=-\nabla f_k$ at every step. One advantage of it is that it requires calculation of the gradinent $\nabla f_k$ but not of second derivatives. However, it can be excruciatingly slow on difficult problems.

2. **The Newton direction** is $p_ k^N=-(\nabla^2f_k)^{-1}\nabla f_k$ assuming for the moment that $\nabla^2f_ k$ is positive definite. The Newton direction is reliable when the difference between the true function $f(x_k+p)$ and its quadratic model $m_ k(p)$ is not too large. Unlike the steepest descent direction, there is a "natural" step length of 1 associated with the Newton direction. The main drawback of the Newton direction is the need of the Hessian $\nabla^2f(x)$.

3. **Quasi-Newton** search directions provide an attractive alternative to Newton's method in that they do not require computation of the Hessian and yet still attain a superlinear rate of convergence. In place of the true Hessian $\nabla^2 f_ k$, they use an approximation $B_k$, which is updated after each step to take account of the additional knowledge gained during the step. The two of the most popular for updating the Hessian approximation $B$ are the symmetric-rank-one(SR1) formula and the BFGS formula:

$$\text{SR1:}\quad B_{k+1}=B_k+\frac{(y_k-B_ks_k)(y_k-B_ks_k)^T}{(y_k-B_ks_k)^Ts_k}$$

$$\text{BFGS:}\quad B_{k+1}=B_k-\frac{B_ks_ks_k^TB_k}{s_k^TB_ks_k}+\frac{y_ky_k^T}{y_k^Ts_k}$$

4. The last class of search directions is that generated by nonlinear conjugate gradient methods. They have the form $p_k=-\nabla f(x_k)+\beta_kp_{k-1}$ where $\beta_k$ is a scalar that ensures that $p_k$ and $p_{k-1}$ are conjugate.

Trust Region
---

In the trust region strategy, the information gathered about $f$ is used to construct a model function $m_k$ whose behavior near the current point $x_k$ is similar to that of the actual objective function $f$.

In other other words, we find the candidate step $p$ by approximately sloving the following subproblem:

$$\min_pm_k(x_k+p),\quad\text{where }x_k+p\text{ lies inside the trust region}$$

---

In a sense, the line saerch and turst region approaches differ in the order in which they choose the direction and the distance of the move to the next line:

- Line search starts by fixing the direction then identifying an appropriate distance, namely the step length $\alpha_k$.

- Trust region first chooses a maxmium distance - the trust region radius $\Delta_k$ - and then seek a direction and step that attain the best improvement possiable subject to this distance constraint.



